{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3DR-eO17geWu"
   },
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EMefrVPCg-60"
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fyU8ZxSAIFOB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Rohan kumar\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator #for data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "LlnCQvOxIt7_",
    "outputId": "e5525300-c0d3-448d-9b79-15e79c2e346c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.15.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxQxCBWyoGPE"
   },
   "source": [
    "## Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MvE-heJNo3GG"
   },
   "source": [
    "### Preprocessing the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "rTbKgq-0I3cA"
   },
   "outputs": [],
   "source": [
    "#Need to preprocess the training set to avoid overfitting. Otherwise, there will be a huge difference betweent the accuracy of training set and testing set.\n",
    "#Hence we need to apply transformations. (for computer vision the way to avoid overfitting is to apply transformation)\n",
    "#Some of geometrical transformations are to sift some of the pixels, rotate a bit of images, horizontal flips, zoom in and zoom out. The technical term refer to all this transformation is image augmentation.\n",
    "\n",
    "train_datagen=ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True) #creating train_dategen object as an instance of the ImageDataGenerator class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8zBVdqnONpFb"
   },
   "source": [
    "rescale is used for feature scaling (here, applied on each and every pixel by dividing theri value by 255, which is just like normalization). Feature scaling is very compulsory for training neural networks.\n",
    "<br>\n",
    "We now need to connect the train_datagen object to our training dataset images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 446
    },
    "id": "_hg1wctoPbhR",
    "outputId": "0c8a76d2-18b0-4399-a4b5-a55588fe25ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set=train_datagen.flow_from_directory(\n",
    "    'dataset/training_set',\n",
    "    target_size=(64,64),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "#flow_from_directory connects the image augmentation tool to images from our training set.\n",
    "#target_size is the final size of the images when they will be fed into the CNN.\n",
    "#batch_size=how many images in each batch.\n",
    "#class_mode= binary, since we have only binary output here Cat/Dog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mrCMmGw9pHys"
   },
   "source": [
    "### Preprocessing the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Zmn73R8GYfO7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen=ImageDataGenerator(rescale=1./255) # no transformation applied, only feature scaling done\n",
    "test_set=test_datagen.flow_from_directory(\n",
    "    'dataset/test_set',\n",
    "    target_size=(64,64),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "af8O4l90gk7B"
   },
   "source": [
    "## Part 2 - Building the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ces1gXY2lmoX"
   },
   "source": [
    "### Initialising the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "bCut7RzBZ_OE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Rohan kumar\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnn=tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u5YJj_XMl5LF"
   },
   "source": [
    "### Step 1 - Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "PfJ2t--xaJdJ"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3, activation='relu', input_shape=(64,64,3)))\n",
    "#kernel_size=size of feature detector\n",
    "#3 in input shape is for colored image, if black & White then use 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tf87FpvxmNOJ"
   },
   "source": [
    "### Step 2 - Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "zZAaPq_3bmfH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Rohan kumar\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xaTOgD8rm4mU"
   },
   "source": [
    "### Adding a second convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "BFAU1MO9cpO2"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3, activation='relu', input_shape=(64,64,3)))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tmiEuvTunKfk"
   },
   "source": [
    "### Step 3 - Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "j4hvlzRjc7yh"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dAoSECOm203v"
   },
   "source": [
    "### Step 4 - Full Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Ecc0to_idSwF"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu')) #we might get better accuracy in the end with a larger number of neurons.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yTldFvbX28Na"
   },
   "source": [
    "### Step 5 - Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "RY2W6okfeMVJ"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6XkI90snSDl"
   },
   "source": [
    "## Part 3 - Training the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vfrFQACEnc6i"
   },
   "source": [
    "### Compiling the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "QFA4aGtMhsuf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Rohan kumar\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ehS-v3MIpX2h"
   },
   "source": [
    "### Training the CNN on the Training set and evaluating it on the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "nrD3CF6wiru9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "WARNING:tensorflow:From C:\\Users\\Rohan kumar\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Rohan kumar\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "250/250 [==============================] - 251s 978ms/step - loss: 0.6619 - accuracy: 0.5979 - val_loss: 0.7106 - val_accuracy: 0.5830\n",
      "Epoch 2/25\n",
      "250/250 [==============================] - 69s 276ms/step - loss: 0.5982 - accuracy: 0.6862 - val_loss: 0.5489 - val_accuracy: 0.7265\n",
      "Epoch 3/25\n",
      "250/250 [==============================] - 55s 219ms/step - loss: 0.5666 - accuracy: 0.7015 - val_loss: 0.5554 - val_accuracy: 0.7290\n",
      "Epoch 4/25\n",
      "250/250 [==============================] - 51s 203ms/step - loss: 0.5379 - accuracy: 0.7293 - val_loss: 0.5138 - val_accuracy: 0.7560\n",
      "Epoch 5/25\n",
      "250/250 [==============================] - 49s 195ms/step - loss: 0.5080 - accuracy: 0.7479 - val_loss: 0.5068 - val_accuracy: 0.7525\n",
      "Epoch 6/25\n",
      "250/250 [==============================] - 48s 193ms/step - loss: 0.4897 - accuracy: 0.7600 - val_loss: 0.5061 - val_accuracy: 0.7570\n",
      "Epoch 7/25\n",
      "250/250 [==============================] - 48s 193ms/step - loss: 0.4789 - accuracy: 0.7684 - val_loss: 0.4629 - val_accuracy: 0.7895\n",
      "Epoch 8/25\n",
      "250/250 [==============================] - 49s 196ms/step - loss: 0.4647 - accuracy: 0.7814 - val_loss: 0.4555 - val_accuracy: 0.7965\n",
      "Epoch 9/25\n",
      "250/250 [==============================] - 63s 253ms/step - loss: 0.4538 - accuracy: 0.7883 - val_loss: 0.5334 - val_accuracy: 0.7445\n",
      "Epoch 10/25\n",
      "250/250 [==============================] - 56s 224ms/step - loss: 0.4351 - accuracy: 0.7971 - val_loss: 0.4451 - val_accuracy: 0.7955\n",
      "Epoch 11/25\n",
      "250/250 [==============================] - 49s 195ms/step - loss: 0.4231 - accuracy: 0.8033 - val_loss: 0.4762 - val_accuracy: 0.7765\n",
      "Epoch 12/25\n",
      "250/250 [==============================] - 50s 201ms/step - loss: 0.4110 - accuracy: 0.8109 - val_loss: 0.5153 - val_accuracy: 0.7515\n",
      "Epoch 13/25\n",
      "250/250 [==============================] - 54s 215ms/step - loss: 0.3999 - accuracy: 0.8185 - val_loss: 0.4424 - val_accuracy: 0.8060\n",
      "Epoch 14/25\n",
      "250/250 [==============================] - 48s 193ms/step - loss: 0.3841 - accuracy: 0.8219 - val_loss: 0.4718 - val_accuracy: 0.8040\n",
      "Epoch 15/25\n",
      "250/250 [==============================] - 49s 195ms/step - loss: 0.3792 - accuracy: 0.8269 - val_loss: 0.4477 - val_accuracy: 0.8090\n",
      "Epoch 16/25\n",
      "250/250 [==============================] - 51s 204ms/step - loss: 0.3670 - accuracy: 0.8300 - val_loss: 0.4525 - val_accuracy: 0.8030\n",
      "Epoch 17/25\n",
      "250/250 [==============================] - 49s 194ms/step - loss: 0.3529 - accuracy: 0.8403 - val_loss: 0.4617 - val_accuracy: 0.8065\n",
      "Epoch 18/25\n",
      "250/250 [==============================] - 47s 189ms/step - loss: 0.3419 - accuracy: 0.8466 - val_loss: 0.4719 - val_accuracy: 0.7935\n",
      "Epoch 19/25\n",
      "250/250 [==============================] - 46s 185ms/step - loss: 0.3303 - accuracy: 0.8534 - val_loss: 0.4876 - val_accuracy: 0.8055\n",
      "Epoch 20/25\n",
      "250/250 [==============================] - 47s 189ms/step - loss: 0.3190 - accuracy: 0.8574 - val_loss: 0.4706 - val_accuracy: 0.8120\n",
      "Epoch 21/25\n",
      "250/250 [==============================] - 47s 187ms/step - loss: 0.3086 - accuracy: 0.8643 - val_loss: 0.5602 - val_accuracy: 0.7805\n",
      "Epoch 22/25\n",
      "250/250 [==============================] - 47s 188ms/step - loss: 0.2911 - accuracy: 0.8721 - val_loss: 0.4532 - val_accuracy: 0.8170\n",
      "Epoch 23/25\n",
      "250/250 [==============================] - 47s 187ms/step - loss: 0.2803 - accuracy: 0.8804 - val_loss: 0.4897 - val_accuracy: 0.8140\n",
      "Epoch 24/25\n",
      "250/250 [==============================] - 47s 188ms/step - loss: 0.2714 - accuracy: 0.8800 - val_loss: 0.4817 - val_accuracy: 0.8185\n",
      "Epoch 25/25\n",
      "250/250 [==============================] - 47s 188ms/step - loss: 0.2520 - accuracy: 0.8959 - val_loss: 0.5711 - val_accuracy: 0.8070\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2152fc5a010>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(x = training_set, validation_data=test_set, epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3PZasO0006Z"
   },
   "source": [
    "## Part 4 - Making a single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "XA86_GzEjnfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 910ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image=image.load_img('dataset/single_prediction/cat_or_dog_1.jpg', target_size=(64,64))\n",
    "# Converting the test_image (PIL format) to numpy array format\n",
    "test_image=image.img_to_array(test_image)\n",
    "test_image=np.expand_dims(test_image, axis=0)\n",
    "result = cnn.predict(test_image/255.0) #normalize the images\n",
    "training_set.class_indices\n",
    "if result[0][0] > 0.5:\n",
    "  prediction='dog'\n",
    "else:\n",
    "  prediction='cat'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
